import os
import pandas as pd
from collections import namedtuple
from qdrant_client import QdrantClient
from qdrant_client.http.models import Distance, VectorParams, PayloadSchemaType
from openai import OpenAI

# Estrutura de dados para upload
Point = namedtuple("Point", ["id", "vector", "payload"])

# Configura√ß√µes via vari√°veis de ambiente
QDRANT_URL     = os.getenv("QDRANT_URL")
QDRANT_KEY     = os.getenv("QDRANT_API_KEY")
COLL_DEFAULT   = os.getenv("QDRANT_COLLECTION", "tecnicos")
COLL_NIP       = os.getenv("QDRANT_COLLECTION_NIP", "nip_reclames")
COLL_AUT       = os.getenv("QDRANT_COLLECTION_AUT", "autorizacao_geral")

EMBED_MODEL    = os.getenv("EMBEDDING_MODEL")
OPENAI_KEY     = os.getenv("OPENAI_API_KEY")

# Clientes
client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_KEY)
openai = OpenAI(api_key=OPENAI_KEY)

# Palavras-chave para NIP/Reclames/ANS/Judiciais
NIP_KEYS = ("nip", "reclame", "ans", "judicial")
# Setores que devem ir para a cole√ß√£o de autoriza√ß√£o geral (sem OPME)
AUT_SETS = {
    "Autoriza√ß√£o",
    "Medicamento",
    "Garantia de Atendimento (Busca de rede)",
}

def choose_collection(setor: str) -> str:
    """
    Decide a cole√ß√£o Qdrant baseada no nome do setor:
    1) Se for um dos AUT_SETS: retorna COLL_AUT
    2) Se contiver qualquer termo de NIP_KEYS (case-insensitive): retorna COLL_NIP
    3) Caso contr√°rio: retorna COLL_DEFAULT
    """
    s = setor.strip().lower()
    if setor in AUT_SETS:
        return COLL_AUT
    if any(key in s for key in NIP_KEYS):
        return COLL_NIP
    return COLL_DEFAULT


def recreate(collection_name: str):
    """
    (Re)cria a cole√ß√£o no Qdrant: apaga se existe, cria com configura√ß√£o de vetor e indexa payload.
    """
    if client.collection_exists(collection_name):
        client.delete_collection(collection_name)
    client.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(size=1536, distance=Distance.COSINE),
    )
    client.create_payload_index(
        collection_name=collection_name,
        field_name="setor",
        field_schema=PayloadSchemaType.KEYWORD,
    )


# Recria as cole√ß√µes antes da ingest√£o
for coll in (COLL_DEFAULT, COLL_NIP, COLL_AUT):
    recreate(coll)

# Carrega CSV de t√©cnicos e setores
csv_path = "data/tecnicos_secoes.csv"
df = pd.read_csv(csv_path, encoding="utf-8-sig")
required_columns = {"Setor", "T√©cnico Respons√°vel", "Responsabilidades", "Exemplos"}
missing = required_columns - set(df.columns)
if missing:
    raise RuntimeError(f"CSV sem colunas obrigat√≥rias: {missing}")

# Buffers de pontos por cole√ß√£o
buffers = {COLL_DEFAULT: [], COLL_NIP: [], COLL_AUT: []}

# Gera√ß√£o de embeddings e prepara√ß√£o de payloads
for idx, row in df.iterrows():
    text = f"Responsabilidades: {row['Responsabilidades']}. Exemplos: {row['Exemplos']}"
    vec = openai.embeddings.create(model=EMBED_MODEL, input=text).data[0].embedding

    payload = {
        "nome": row["T√©cnico Respons√°vel"].strip(),
        "setor": row["Setor"].strip(),
        "responsabilidades": str(row["Responsabilidades"]).strip(),
        "exemplos": str(row["Exemplos"]).strip(),
    }

    coll = choose_collection(row["Setor"])
    buffers[coll].append(Point(id=int(idx), vector=vec, payload=payload))

# Upload em batch para cada cole√ß√£o
for coll, points in buffers.items():
    if not points:
        continue
    client.upload_points(collection_name=coll, points=points, batch_size=256)
    print(f"‚úî  {len(points)} pontos ‚Üí {coll}")

print("üöÄ Ingest√£o conclu√≠da.")
